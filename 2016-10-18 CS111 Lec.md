## COM SCI 111, Lec 10/18/2016, Part 1
### Inter-process Communication: Introduction
provided through system calls, typically requiring activities from both communicating processes, mediated each step by the OS
**Synchronous IPC**: easier for programmers
Write blocks (next continue running next instruciton) unitil message delivered; read blocks until a new message is available
**Asynchronous IPC**: more efficient
Write returns when system accepts message; required mechanism to learn of errors
Read returns if no message available; involves mechanism to learn of new messages

`create/destroy an IPC channel --> write/send --> read/receive --> channel content query (how much data in total) --> connection-related query (who are end-points)`

**Streams**: a continous stream of bytes
**Messages/Datagrams**: a sequence of distinct messags, delivery is typically all or nothing

*Flow control*: making sure a fast sender doesn't overwhelm a slow receiver
Sender-side: block sender; receiver-side: flush old messages

IPC reliability: requests and responses can be lost across a network, sometimes even on a single machine (Eg. the receiver is not responding, etc.)
Problems to consider:
	1. When do we tell that the message is sent? (Eg. added to queue, receiver has read it?)
	2. How does the system attempt delivery? (Eg. handle retransmissions?)
	3. What to do when receiver crashes and restarts? (Does the sender expecte it to continue receiving messages?)

### Inter-process Communication: Types
**Pipelines**: a simple byte stream of data flows through a series of programs
	Data buffered in the OS, no security/privacy issues all under control of a single user
**Socket**: connection between addresses/ports
	Many data options: streams, messages, remote procedure calls, etc.
	Complex flow control and error handling
	Trust/security/privacy/integrity
**Mailboxes** and **Named pipes**: a client/server rendezvous point; a compromise between sockets and pipes
	A server *awaits client connections*, it may be as simple as a pipe once open
	Client/server must be on the same system
**Shared memory**: OS arranges for processes to share read/write memory segments, mapped into multiple process' address spaces
	OS not involved in data transfer nor data protection, so very fast
	Applications must provide own control of sharing, potentially complicated: Eg. race conditions by more than one process writing, etc.
	Only works on local machine

### Synchronization
*Race condition*: what happends depends on execution order of processes/threads running in parallel.
Parallel execution reduces predictability of process behavior
Two major problems in synchronization:
1. *Critical section serialization*
2. *Notification of asynchronous completion*

### Sychronization: Critical section serialization
*Critical section*: a resource shared by multiple threads; use of the resources changes its state, correctness depends on execution order
	Eg. Updating a file, re-entrant signals, multithreaded banking
	Each thread doing part of the critical section before any of them do all of it
	*Mutual exclusion*: ensure that only one thread can execute a critical seciton at a time

**Interrupt Disables**: temporariliy block some of all interrupts, to prevent time-slice and and re-entry of device driver code
	Device drivers handles OS interrupts for requests; if another interrupt arrives when running instructions dealing with the previous one, there may be race condition. Eg. Direct Memory Access (DMA)
	Effectiveness: useless against multiprocessor
	Danger: 
		1. requires use of priviledged instructions, potential danger such as disabling preemptive scheduling, etc.
		2. may delay important operations: processing received data, etc.
		3. Risk of *deadlock*
