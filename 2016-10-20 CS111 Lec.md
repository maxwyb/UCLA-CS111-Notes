## COM SCI 111, Lec 10/20/2016
### Syncronization: Critical Section Serialization
**Mutual exclusion**: ensure that only one thread can execute a critical section at a time
Critical sections:
	1. invovles updates to object state
	2. invovles multi-step operations; object state inconsistent until operation finishes
	3. correct operation requires mutual exclusion

Critical sections are most common for multithreaded applications, and can also happen with processes sharing OS resources
Critical sections in OS; shared data: process state variables, resource pools, device driver state
	Logical parallelism: creatd by preemptive scheduling and asychronous interrupts
	Physical parallelism: shared memory, symmetric multi-processors

Using mutual exculsions allow us to achieve **atomicity** of a critical section:
*Before or After atomicity*: B enters critical section after A completes
*All or None atomicity*: an update started will complete, an uncompleted update has no effect.

CPU Instructions are uninterruptable
	Read/modify/write operations, which can be applied to 1-8 continuous bytes
	increment/decrement, and/or/xor
	test-and-set, exchange, compare-and-swap
Either do entire critical section in one atomic instruction, or use atomic instructions to implement locks

### Synchronization: Built-in Instructions
**Test-and-Set**, **Compare-and-Swap**: functions built into processors' instruction sets

Multi-thread Safe Data Structures and Operations:
Carefully program data strcture to perform ciritical operations with one instruction, but unusable as a waiting mechanism
	Eg. push an element to a singly linked FIFO list: the third statement is actually updating that list, `do-while()` loop spin and waits
	Progress: no possibility of deadlock
	Fairness: small possibility of brief spins
	Performance: expensive instructions but cheaper than system calls

### Synchronization: Locks
*Locks*: the party holding a lock can access the critical section, the others cannot
Example: updating a counter
```c
pthread_mutex_t lock;
ptherad_mutex_init(&lock, NULL);
if (pthread_mutex_lock(&lock) == 0) {
	counter += 1;
	pthread_mutex_unlock(&lock);
}
```
`pthread` third-party library: No OS protection to guarantee that every critical section has lock added; program is screwed if you forget to add lock in one thread

**Spin Locks**
+ Properly enforces access to critical sections, easy to program.
- bugs may lead to infinite spin-waits
Locks and Interrupts: potentially enter infinite loops; interrupts is automatically disabled when interrupt handler function is called.

Using atomic instructions to implement a lock: use one single processor instruction, as operation of locking and unlocking a lock is itself a critical section

Different forms of spin lock:
1. Lock and wait
2. Non-blocking: return an error if resource is unavailable
3. Timed wait: block a specified maximum time
4. Spin and wait (`futex`): spin briefly and then join a waiting list for the resource
5. Strict FIFO: join a waiting list following FIFO, other options may consider process priority, etc.

*Asynchronous Completion Problem*: how to perform waits without killing performance
**Spin waiting**
+ when awaited operation is guaranteed to be soon, as spinning is less expensive than sleep/wakeup
+ when contention for processor is expected to be rare
- waste CPU cycles, memory and bus bandwidth

**Yield and Spin**: check a few times if the event occured, and then yield. Sooner or later the process get rescheduled and then check again; repeat until event is ready.
	A state machine: *running*, *blocked* and *ready* states
- Extra context switches, still wastes CPU cycles on spinning
- Works poorly with multiple waiters

**Condition Variables**: generally provided by the OS. Blocks a process or thread when condition variable is used; then unblocks it when observes teh desired event
*Waiting list* for processes: all events need a list, as each thread should wake up only when its own event arrives
	`pthread_cond_wait`: wakeup at least one blocked thread in the waiting list when the event occurs
	`pthread_cond_broadcast`: wakeup all blocked threads; potentially wasteful if the event can only be consumed once
	
Implementing a waiting list, which is a shared data structure and may be protected by a lock!
