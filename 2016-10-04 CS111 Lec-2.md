## COM SCI 111, Lec 10/04/2016, Part 2
### Scheduling: Introduction
OS making decisions for which client uses the resource next, including I/O requests and network communication.
*The Process Queue*: OS keeps a queue of processes that are ready to run, ordered by whichever one should run next.
	Grab the first one on the queue when scheduling a new process

Several scheduling approaches:
1. Time sharing: each user gets an equal share of the CPU
2. Batch: maximize total system throughput (total work done)
3. Real-time: critical operations must happen on time
   *Preemptive* and *Non-preemptive scheduling*: if a scheduled work always runs to completion
   Non-preemptive: producing high throughput, but poor response time
   Preemptive: works well with real-time and priority scheduling

*Dispatching*: the scheduler moves jobs into and out of processor
	Ready queue -> dispatcher -> context switcher (decision-making) -> context switcher (physical work) -> CPU

### Scheduling: Quantifying scheduler performance
Criteria:
- Throughput (processes done per second, operations per second)
- Delay (milliseconds)
- etc.

Process execution: time spent running, time waiting for resources or completion (by *resource manager*), time spent waiting to be run (by *scheduler*)
Throughput VS. Load curve: not ideal because takes time to dispatch a process (*overhead*)
Response time VS. Load curve: load arrives a lot faster than it's serviced, exceeds queue size and lots of stuff get dropped
